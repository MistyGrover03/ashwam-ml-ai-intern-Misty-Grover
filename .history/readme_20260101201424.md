# Evidence-Grounded Extraction & Evaluation

## üìå Overview

This project provides a **strict, evidence-based evaluation framework** for information extracted from **human-written health journals**.

The system evaluates predicted extractions against human-annotated gold data using **exact textual evidence**, ensuring that **no unsupported or hallucinated information** is counted.

> **Only what is explicitly written in the journal can be scored.**

---

## üéØ Core Objectives

- Evaluate extracted health-related facts safely  
- Enforce exact evidence grounding  
- Avoid hallucinations and assumptions  
- Provide transparent and reproducible metrics  

---

## üìÇ Project Structure 

Project root directory:

data  
- journals.jsonl  
- gold.jsonl  
- sample_predictions.jsonl  

ashwam_eval  
- cli.py ‚Äî Command-line interface  
- extract.py ‚Äî Data loading utilities  
- score.py ‚Äî Evaluation logic  

out  
- score_summary.json  
- per_journal_scores.jsonl  

README.md  

---

## üìÑ Input Files

### journals.jsonl

Contains the original journal text written in natural language.  
This file acts as the **source of truth for evidence validation**.

Example:
```json
{
  "journal_id": "J001",
  "text": "I felt anxious and had trouble sleeping last night."
}
gold.jsonl
Human-annotated reference data used only for evaluation.
Each journal contains multiple labeled items with exact evidence spans.

Example:
{
  "journal_id": "J001",
  "items": [
    {
      "domain": "emotion",
      "evidence_span": "felt anxious",
      "polarity": "present",
      "arousal_bucket": "high",
      "time_bucket": "today"
    }
  ]
}
sample_predictions.jsonl 
Example predictions used to test the evaluation pipeline.
No real model inference is required.

Example:
{
  "journal_id": "J001",
  "items": [
    {
      "domain": "emotion",
      "evidence_span": "felt anxious",
      "polarity": "present",
      "arousal_bucket": "high",
      "time_bucket": "today"
    }
  ]
}
üßæ Prediction Representation
Internally, predictions are flattened into one JSON object per extracted fact.

Example:
{
  "journal_id": "J001",
  "domain": "emotion",
  "evidence_span": "felt anxious",
  "polarity": "present",
  "arousal_bucket": "high",
  "time_bucket": "today"
}

### Rules
- One object represents one fact  
- evidence_span must be copied exactly from the journal  
- Predictions without evidence are discarded  

‚öôÔ∏è Evaluation Logic
 A predicted item is considered a True Positive only if:
- journal_id matches
- domain matches
- evidence_span overlaps with the gold evidence

Not Used
‚ùå Label matching
‚ùå Synonym matching
‚ùå Semantic inference
Evaluation is strictly evidence-driven.

üìä Metrics Computed
Core Metrics
- Precision
- Recall
- F1-score
Attribute Accuracy
- Polarity accuracy
- Bucket accuracy (intensity/arousal + time)
Evidence Validation
- Evidence coverage rate
- Percentage of predictions whose evidence exists in the journal text

üõ°Ô∏è Hallucination Prevention
The system enforces safety through:
- Discarding predictions without evidence
- Verifying evidence spans against journal text
- Scoring only evidence-backed facts
This guarantees zero hallucinated evaluation.

## ‚ñ∂Ô∏è Running the Evaluation

Run the following command from the project root:

-----------------------------------------
$ python -m ashwam_eval.cli run --data ./data --out ./out
-----------------------------------------

What This Command Does
- Loads journal, gold, and prediction data
- Executes evidence-based matching
- Computes evaluation metrics
- Writes output files to the out/ directory


üìÅ Output Files
- out/score_summary.json
Contains overall evaluation metrics:
{
  "precision": 0.75,
  "recall": 0.60,
  "f1": 0.67,
  "polarity_accuracy": 0.80,
  "bucket_accuracy": 0.70,
  "evidence_coverage": 1.0
}
- out/per_journal_scores.jsonl
Journal-level performance breakdown:

{
  "journal_id": "J001",
  "tp": 2,
  "fp": 1,
  "fn": 0
}
üìâ Why Recall May Be Low
Low recall is expected and intentional.
- The system does not guess
- It avoids unsupported extraction
- It prioritizes safety over coverage
Lower recall reflects safe abstention, not failure